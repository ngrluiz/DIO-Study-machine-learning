# Transfer-Learning-em-uma-rede-de-Deep-Learning
O projeto consiste em aplicar o mÃ©todo de Transfer Learning em uma rede de Deep Learning na linguagem Python no ambiente COLAB. 


# Transfer Learning em uma Rede de Deep Learning

AplicaÃ§Ã£o prÃ¡tica de **Transfer Learning** para classificaÃ§Ã£o de imagens com notebook Jupyter (otimizado para **Google Colab**). O objetivo Ã© treinar rapidamente um classificador reaproveitando pesos prÃ©-treinados (ex.: ResNet/EfficientNet/MobileNet), com pipeline simples, reproducÃ­vel e pronto para datasets pequenos.

---

## ğŸš€ Como executar

### OpÃ§Ã£o A â€” Google Colab (recomendado)
1. Abra o notebook `transfer_learning.ipynb` no Colab.
2. Em **Runtime** â†’ **Change runtime type**, selecione **GPU**.
3. Execute as cÃ©lulas de preparaÃ§Ã£o do ambiente (instalaÃ§Ã£o de pacotes) e siga o passo a passo.

### OpÃ§Ã£o B â€” Local
```bash
# Clonar o repositÃ³rio
git clone https://github.com/ngrluiz/Transfer-Learning-em-uma-rede-de-Deep-Learning.git
cd Transfer-Learning-em-uma-rede-de-Deep-Learning

# (Opcional) criar ambiente virtual
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows (PowerShell)
.venv\Scripts\Activate.ps1

# Instalar dependÃªncias mÃ­nimas
pip install -r requirements_local.txt

# Abrir o Jupyter
jupyter notebook
```
> Se preferir, copie/cole o conteÃºdo do notebook para um novo `.ipynb` em seu ambiente.

---

## ğŸ—‚ Estrutura esperada de dados (exemplo)

```
data/
  train/
    classeA/
    classeB/
  val/
    classeA/
    classeB/
```
- Use `train/` e `val/` com subpastas por classe (padrÃ£o *ImageFolder* do PyTorch ou *flow_from_directory* do Keras).
- No Colab, vocÃª pode montar o Google Drive e apontar para `data/`.

---

## âš™ï¸ Pipeline (alto nÃ­vel)

1. **Carga e augmentations** do conjunto de dados.
2. **Backbone prÃ©-treinado** (ImageNet): congela-se a base e treina-se o *head* (camadas finais).
3. **(Opcional)** *Fine-tuning* parcial: descongelar Ãºltimas camadas do backbone com *learning rate* menor.
4. **AvaliaÃ§Ã£o**: acurÃ¡cia, *loss*, matriz de confusÃ£o e F1-score.
5. **Checkpoint**: salvar melhor modelo por mÃ©trica de validaÃ§Ã£o.

---

## ğŸ”§ HiperparÃ¢metros sugeridos

- `img_size`: 224Ã—224  
- `batch_size`: 16â€“64 (ajuste conforme VRAM)  
- `base_lr` (cabeÃ§a): 1e-3  
- `ft_lr` (fine-tuning): 1e-4 ou 1e-5  
- `epochs`: 10â€“30 (use *early stopping*)

---

## ğŸ§ª Dicas e troubleshooting

- **GPU no Colab**: ative em *Runtime* â†’ *Change runtime type* â†’ *GPU*.
- **OOM (falta de VRAM)**: reduza `batch_size` ou `img_size`.
- **Overfitting**: aumente augmentations, adote *dropout*, use *early stopping*.
- **Conflito de versÃµes**: no Colab, prefira instalar nas cÃ©lulas do notebook; localmente, fixe versÃµes em `requirements_local.txt`.

---

## ğŸ“¦ DependÃªncias

HÃ¡ dois perfis de requisitos:
- `requirements_colab.txt`: minimalista, pensado para o ambiente do Colab.
- `requirements_local.txt`: inclui *pins* e comentÃ¡rios para execuÃ§Ã£o local.

> O notebook pode instalar bibliotecas adicionais conforme o backbone escolhido. Ajuste conforme necessÃ¡rio.

---

## ğŸ“ LicenÃ§a

Se ainda nÃ£o houver licenÃ§a no repositÃ³rio, recomenda-se **MIT** ou **Apache-2.0**.

---

## ğŸ¤ ContribuiÃ§Ãµes

Pull requests sÃ£o bem-vindas! Abra uma *Issue* para bugs, melhorias e novas ideias (ex.: suportar novos backbones, mÃ©tricas extras, *wandb* para tracking, etc.).
